import os
import sys
import subprocess
import zipfile
import tempfile
import requests
from tqdm import tqdm
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import json

# ComfyUI èŠ‚ç‚¹åŸºç±»
class HiveModelDownloader:
    """
    æ¨¡å‹ä¸‹è½½å™¨èŠ‚ç‚¹
    ç”¨æˆ·å¯ä»¥ç²˜è´´æ¨¡å‹æ–‡ä»¶çš„ä¸‹è½½åœ°å€ï¼Œé€‰æ‹©ä¿å­˜ç›®å½•ï¼Œç„¶åä¸‹è½½
    """
    @classmethod
    def INPUT_TYPES(cls):
        # è·å– models ç›®å½•çš„å­ç›®å½•åˆ—è¡¨
        def get_models_subdirs():
            try:
                current_dir = os.path.dirname(os.path.abspath(__file__))
                comfyui_root = None
                check_dir = current_dir
                for _ in range(5):
                    if os.path.exists(os.path.join(check_dir, "models")):
                        comfyui_root = check_dir
                        break
                    parent = os.path.dirname(check_dir)
                    if parent == check_dir:
                        break
                    check_dir = parent
                
                if comfyui_root:
                    models_dir = os.path.join(comfyui_root, "models")
                    if os.path.exists(models_dir):
                        subdirs = []
                        for item in os.listdir(models_dir):
                            item_path = os.path.join(models_dir, item)
                            if os.path.isdir(item_path):
                                subdirs.append(item)
                        return subdirs if subdirs else ["checkpoints", "loras", "vae", "upscale_models", "controlnet"]
            except:
                pass
            return ["checkpoints", "loras", "vae", "upscale_models", "controlnet"]
        
        models_subdirs = get_models_subdirs()
        
        return {
            "required": {
                "url": ("STRING", {
                    "name": "æ¨¡å‹åœ°å€/model_url",
                    "multiline": False,
                    "default": "",
                    "placeholder": "è¯·å°†æ¨¡å‹åœ°å€ç²˜è´´è¿›æ¥",
                    "tooltip": "è¯·å°†æ¨¡å‹åœ°å€ç²˜è´´è¿›æ¥ / please paste the model address here"
                }),
                "save_directory": (models_subdirs, {
                    "name": "é€‰æ‹©æ¨¡å‹ä¿å­˜ç›®å½•/select model save directory",
                    "tooltip": "é€‰æ‹©æ¨¡å‹ä¿å­˜ç›®å½• / select the model save directory",
                    "default": models_subdirs[0] if models_subdirs else "checkpoints"
                }),
            },
            "optional": {}
        }
    
    RETURN_TYPES = ()
    FUNCTION = "download_model"
    OUTPUT_NODE = True
    CATEGORY = "Hive/Download"
    # æ³¨æ„è¯­è¨€æ–‡ä»¶ä¸­ä¸èƒ½ç”¨@ç¬¦å·
    DESCRIPTION = "æ¨¡å‹ä¸‹è½½å™¨ - ç²˜è´´æ¨¡å‹æ–‡ä»¶çš„ä¸‹è½½åœ°å€ï¼Œé€‰æ‹©ä¿å­˜ç›®å½•ï¼Œç„¶åä¸‹è½½ã€‚æ”¯æŒå¤šçº¿ç¨‹ä¸‹è½½ä»¥æé«˜é€Ÿåº¦ã€‚/ Model downloader node - paste the download address of model files, select a save directory, and download them. Supports multi-threaded downloading for faster speeds. - Github: https://github.com/luguoli - ğŸ“§Email: luguoliï¹«vip.qq.com"


    
    def download_model(self, url, save_directory="checkpoints"):
        """
        ä¸‹è½½æ¨¡å‹æ–‡ä»¶
        
        Args:
            url: æ¨¡å‹æ–‡ä»¶çš„ä¸‹è½½åœ°å€
            save_directory: ä¿å­˜ç›®å½•åç§°ï¼ˆmodels ä¸‹çš„å­ç›®å½•ï¼‰
        
        Returns:
            status: ä¸‹è½½çŠ¶æ€ä¿¡æ¯
        """
        if not url or not url.strip():
            return {"ui": {"text": ["é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„ä¸‹è½½åœ°å€ / Error: Please provide a valid download URL"]}}
        
        url = url.strip()
        
        try:
            # å°è¯•æ‰¾åˆ° ComfyUI çš„ models ç›®å½•
            current_dir = os.path.dirname(os.path.abspath(__file__))
            # å‘ä¸ŠæŸ¥æ‰¾ ComfyUI æ ¹ç›®å½•
            comfyui_root = None
            check_dir = current_dir
            for _ in range(5):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾5å±‚
                if os.path.exists(os.path.join(check_dir, "models")):
                    comfyui_root = check_dir
                    break
                parent = os.path.dirname(check_dir)
                if parent == check_dir:
                    break
                check_dir = parent
            
            if comfyui_root:
                save_directory_path = os.path.join(comfyui_root, "models", save_directory)
            else:
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„ models æ–‡ä»¶å¤¹
                save_directory_path = os.path.join(current_dir, "models", save_directory)
            
            save_directory_path = os.path.abspath(save_directory_path)
            
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            os.makedirs(save_directory_path, exist_ok=True)
            
            # è·å–æ–‡ä»¶å
            filename = os.path.basename(url.split('?')[0])  # ç§»é™¤æŸ¥è¯¢å‚æ•°
            if not filename or '.' not in filename:
                # å¦‚æœæ— æ³•ä»URLè·å–æ–‡ä»¶åï¼Œå°è¯•ä»Content-Dispositionè·å–
                filename = "downloaded_model.bin"
            
            save_path = os.path.join(save_directory_path, filename)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(save_path):
                file_size = os.path.getsize(save_path)
                file_size_mb = file_size / (1024 * 1024)
                return {"ui": {"text": [f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½ / File already exists, skipping download\næ–‡ä»¶è·¯å¾„ / File path: {save_path}\næ–‡ä»¶å¤§å° / File size: {file_size_mb:.2f} MB\n\nå¦‚éœ€é‡æ–°ä¸‹è½½ï¼Œè¯·å…ˆåˆ é™¤ç°æœ‰æ–‡ä»¶æˆ–æ›´æ”¹ä¿å­˜ä½ç½® / To re-download, please delete the existing file or change the save location"]}}
            
            # å¼€å§‹ä¸‹è½½
            print(f"å¼€å§‹ä¸‹è½½ / Starting download: {url}")
            print(f"ä¿å­˜åˆ° / Saving to: {save_path}")
            status_msg = f"å¼€å§‹ä¸‹è½½ / Starting download: {url}\n"
            
            # å…ˆè·å–æ–‡ä»¶ä¿¡æ¯ï¼ˆä½¿ç”¨ä¸´æ—¶sessionï¼Œé¿å…è¿æ¥å¤ç”¨é—®é¢˜ï¼‰
            with requests.Session() as tmp_session:
                tmp_session.headers.update({
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })
                head_response = tmp_session.head(url, allow_redirects=True, timeout=30)
                head_response.raise_for_status()
            
            # è·å–æ–‡ä»¶å¤§å°
            total_size = int(head_response.headers.get('content-length', 0))
            
            # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦æ”¯æŒ Range è¯·æ±‚ï¼ˆå¤šçº¿ç¨‹ä¸‹è½½éœ€è¦ï¼‰
            supports_range = head_response.headers.get('accept-ranges', '').lower() == 'bytes'
            
            if total_size > 0 and supports_range:
                # ä½¿ç”¨å¤šçº¿ç¨‹ä¸‹è½½ï¼ˆæ”¯æŒ Range è¯·æ±‚ï¼‰
                # å¯¹äºè¶…å¤§æ–‡ä»¶ï¼ˆ>10GBï¼‰ï¼Œé™åˆ¶çº¿ç¨‹æ•°é¿å…è¿‡å¤šä¸´æ—¶æ–‡ä»¶
                # æ¯ä¸ªçº¿ç¨‹å¤„ç†çº¦500MB-1GBçš„æ•°æ®æ¯”è¾ƒåˆç†
                if total_size > 10 * 1024 * 1024 * 1024:  # å¤§äº10GB
                    num_threads = min(8, max(4, total_size // (1024 * 1024 * 1024)))  # æ¯GBä¸€ä¸ªçº¿ç¨‹ï¼Œæœ€å¤š8ä¸ª
                else:
                    num_threads = min(8, max(4, total_size // (10 * 1024 * 1024)))  # æ¯10MBä¸€ä¸ªçº¿ç¨‹ï¼Œæœ€å¤š8ä¸ª
                chunk_size = total_size // num_threads
                
                print(f"ä½¿ç”¨ {num_threads} ä¸ªçº¿ç¨‹è¿›è¡Œå¤šçº¿ç¨‹ä¸‹è½½... / Using {num_threads} threads for multi-threaded download...")
                
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶æ¥å­˜å‚¨å„ä¸ªåˆ†ç‰‡
                temp_files = {}  # ä½¿ç”¨å­—å…¸ï¼Œä»¥ chunk_id ä¸ºé”®
                threads = []
                downloaded_chunks = [0] * num_threads
                lock = threading.Lock()
                
                def download_chunk(chunk_id, start, end):
                    """ä¸‹è½½æ–‡ä»¶çš„ä¸€ä¸ªåˆ†ç‰‡"""
                    # ã€å…³é”®ä¿®å¤ã€‘æ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„Sessionï¼Œé¿å…è¿æ¥æ± ç«äº‰å’Œæ­»é”
                    local_session = requests.Session()
                    local_session.headers.update({
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    })
                    
                    temp_file_path = None
                    temp_file = None
                    try:
                        headers = {'Range': f'bytes={start}-{end}'}
                        expected_size = end - start + 1
                        
                        # å°†ä¸´æ—¶æ–‡ä»¶æ”¾åœ¨ç›®æ ‡ç›®å½•é™„è¿‘ï¼Œé¿å…ç³»ç»Ÿä¸´æ—¶ç›®å½•ç©ºé—´ä¸è¶³çš„é—®é¢˜
                        # å¯¹äºè¶…å¤§æ–‡ä»¶ï¼Œè¿™æ ·å¯ä»¥æ›´å¥½åœ°æ§åˆ¶ä¸´æ—¶æ–‡ä»¶ä½ç½®
                        temp_dir = os.path.dirname(save_path)
                        temp_file_path = os.path.join(temp_dir, f'.{os.path.basename(save_path)}.part{chunk_id}.tmp')
                        
                        temp_file = open(temp_file_path, 'wb')
                        
                        # ä½¿ç”¨é”ä¿æŠ¤å­—å…¸å†™å…¥æ“ä½œ
                        with lock:
                            temp_files[chunk_id] = temp_file_path
                        
                        # å¯¹äºä¸­ç­‰å¤§å°çš„åˆ†ç‰‡ï¼ˆ<100MBï¼‰ï¼Œä¸ä½¿ç”¨ streamï¼Œç›´æ¥è·å–å…¨éƒ¨å†…å®¹
                        # è¿™æ ·å¯ä»¥é¿å…æµå¼è¯»å–å¯èƒ½çš„é˜»å¡é—®é¢˜
                        if expected_size < 100 * 1024 * 1024:  # å°äº100MB
                            # ä¸ä½¿ç”¨ stream=Trueï¼Œç›´æ¥è·å–å®Œæ•´å“åº”
                            response = local_session.get(url, headers=headers, stream=False, timeout=(30, 300))
                            response.raise_for_status()
                            
                            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                            if response.status_code not in [200, 206]:
                                raise Exception(f"åˆ†ç‰‡ {chunk_id} å“åº”çŠ¶æ€ç é”™è¯¯: {response.status_code} / Chunk {chunk_id} response status code error: {response.status_code}")
                            
                            content = response.content
                            if not content or len(content) == 0:
                                raise Exception(f"åˆ†ç‰‡ {chunk_id} å“åº”å†…å®¹ä¸ºç©º / Chunk {chunk_id} response content is empty")
                            
                            chunk_downloaded = len(content)
                            temp_file.write(content)
                            temp_file.flush()
                            
                            # æ›´æ–°è¿›åº¦
                            with lock:
                                downloaded_chunks[chunk_id] = chunk_downloaded
                        else:
                            # å¯¹äºå¤§åˆ†ç‰‡ï¼ˆ>=100MBï¼‰ï¼Œç»Ÿä¸€ä½¿ç”¨æµå¼è¯»å–
                            # ä¹‹å‰çš„ç›´æ¥è¯»å–æ–¹å¼å¯¹äºå¤§æ–‡ä»¶å¯èƒ½ä¼šé˜»å¡ï¼Œæ‰€ä»¥æ”¹ä¸ºç»Ÿä¸€ä½¿ç”¨æµå¼ä¸‹è½½
                            # æ ¹æ®åˆ†ç‰‡å¤§å°åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´
                            min_speed_mbps = 1.0  # æœ€ä½1MB/s
                            estimated_time = (expected_size / (1024 * 1024)) / min_speed_mbps  # ç§’
                            # è¿æ¥è¶…æ—¶60ç§’ï¼Œè¯»å–è¶…æ—¶ä¸ºä¼°ç®—æ—¶é—´çš„2å€ï¼Œæœ€å°‘300ç§’ï¼Œæœ€å¤š1800ç§’ï¼ˆ30åˆ†é’Ÿï¼‰
                            read_timeout = max(300, min(1800, int(estimated_time * 2)))
                            chunk_timeout = (60, read_timeout)
                            
                            response = local_session.get(url, headers=headers, stream=True, timeout=chunk_timeout)
                            response.raise_for_status()
                            
                            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                            if response.status_code not in [200, 206]:
                                raise Exception(f"åˆ†ç‰‡ {chunk_id} å“åº”çŠ¶æ€ç é”™è¯¯: {response.status_code} / Chunk {chunk_id} response status code error: {response.status_code}")
                            
                            # æ£€æŸ¥Content-Rangeå¤´ï¼Œç¡®ä¿å“åº”æ˜¯æ­£ç¡®çš„èŒƒå›´
                            content_range = response.headers.get('Content-Range', '')
                            if content_range and chunk_id == 0:
                                # éªŒè¯ç¬¬ä¸€ä¸ªåˆ†ç‰‡çš„èŒƒå›´æ˜¯å¦æ­£ç¡®
                                if 'bytes 0-' not in content_range:
                                    print(f"[è­¦å‘Š] åˆ†ç‰‡0çš„Content-Rangeå¯èƒ½å¼‚å¸¸: {content_range} / [Warning] Chunk 0 Content-Range may be abnormal: {content_range}")
                            
                            chunk_downloaded = 0
                            # æ ¹æ®åˆ†ç‰‡å¤§å°è°ƒæ•´æ›´æ–°é—´éš”ï¼šå¤§æ–‡ä»¶æ›´æ–°é¢‘ç‡å¯ä»¥ä½ä¸€äº›
                            if expected_size > 1024 * 1024 * 1024:  # >1GB
                                update_interval = 50 * 1024 * 1024  # æ¯50MBæ›´æ–°ä¸€æ¬¡è¿›åº¦
                                flush_interval = 100 * 1024 * 1024  # æ¯100MBåˆ·æ–°ä¸€æ¬¡ï¼ˆå‡å°‘IOï¼‰
                            else:
                                update_interval = 5 * 1024 * 1024  # æ¯5MBæ›´æ–°ä¸€æ¬¡è¿›åº¦
                                flush_interval = 20 * 1024 * 1024  # æ¯20MBåˆ·æ–°ä¸€æ¬¡
                            
                            last_update_size = 0
                            last_flush_size = 0
                            
                            # ä½¿ç”¨ iter_content æµå¼è¯»å–
                            # ç»Ÿä¸€ä½¿ç”¨1MBå—å¤§å°ï¼Œé¿å…è¿‡å¤§Bufferè§¦å‘é˜²ç«å¢™æµé‡æ•´å½¢ï¼Œæé«˜ç¨³å®šæ€§
                            iter_chunk_size = 1024 * 1024  # ç»Ÿä¸€ä½¿ç”¨1MBå—
                            has_data = False
                            last_chunk_time = time.time()  # è®°å½•æœ€åä¸€æ¬¡æ”¶åˆ°æ•°æ®çš„æ—¶é—´
                            chunk_read_timeout = 120  # å¦‚æœ120ç§’æ²¡æœ‰æ”¶åˆ°æ–°æ•°æ®å—ï¼Œè®¤ä¸ºè¿æ¥å¯èƒ½ä¸­æ–­
                            
                            # å¯¹äºç¬¬ä¸€ä¸ªåˆ†ç‰‡ï¼Œç«‹å³æ›´æ–°è¿›åº¦ï¼ˆå³ä½¿åªæœ‰å¾ˆå°‘çš„æ•°æ®ï¼‰ï¼Œç¡®ä¿è¿›åº¦å¯è§
                            first_chunk_received = False
                            
                            for chunk in response.iter_content(chunk_size=iter_chunk_size):
                                current_time = time.time()
                                if chunk:
                                    has_data = True
                                    last_chunk_time = current_time
                                    temp_file.write(chunk)
                                    chunk_downloaded += len(chunk)
                                    
                                    # å¯¹äºç¬¬ä¸€ä¸ªåˆ†ç‰‡çš„ç¬¬ä¸€ä¸ªæ•°æ®å—ï¼Œç«‹å³æ›´æ–°è¿›åº¦
                                    if chunk_id == 0 and not first_chunk_received:
                                        with lock:
                                            downloaded_chunks[chunk_id] = chunk_downloaded
                                        first_chunk_received = True
                                    
                                    # æ¯æ¬¡æ”¶åˆ°æ•°æ®éƒ½æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°å’Œæ›´æ–°è¿›åº¦
                                    if chunk_downloaded - last_flush_size >= flush_interval:
                                        temp_file.flush()
                                        last_flush_size = chunk_downloaded
                                    
                                    # æ›´é¢‘ç¹åœ°æ›´æ–°è¿›åº¦ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå‰å‡ ä¸ªæ•°æ®å—
                                    # å‰10MBæ¯1MBæ›´æ–°ä¸€æ¬¡ï¼Œä¹‹åæŒ‰æ­£å¸¸é—´éš”
                                    force_update = chunk_downloaded < 10 * 1024 * 1024 and (chunk_downloaded - last_update_size >= 1024 * 1024)
                                    if force_update or chunk_downloaded - last_update_size >= update_interval:
                                        with lock:
                                            downloaded_chunks[chunk_id] = chunk_downloaded
                                        last_update_size = chunk_downloaded
                                else:
                                    # å¦‚æœæ”¶åˆ°ç©ºå—ï¼Œæ£€æŸ¥æ˜¯å¦è¶…æ—¶
                                    if has_data and current_time - last_chunk_time > chunk_read_timeout:
                                        raise Exception(f"åˆ†ç‰‡ {chunk_id} è¯»å–è¶…æ—¶ï¼ˆ{chunk_read_timeout}ç§’æœªæ”¶åˆ°æ•°æ®ï¼Œå·²ä¸‹è½½ {chunk_downloaded / 1024 / 1024:.2f} MBï¼‰ / Chunk {chunk_id} read timeout ({chunk_read_timeout}s no data, downloaded {chunk_downloaded / 1024 / 1024:.2f} MB)")
                            
                            if not has_data or chunk_downloaded == 0:
                                raise Exception(f"åˆ†ç‰‡ {chunk_id} æœªä¸‹è½½åˆ°ä»»ä½•æ•°æ® / Chunk {chunk_id} downloaded no data")
                            
                            # æœ€ååˆ·æ–°å¹¶æ›´æ–°è¿›åº¦
                            temp_file.flush()
                            with lock:
                                downloaded_chunks[chunk_id] = chunk_downloaded
                        
                        # æœ€ååˆ·æ–°å¹¶æ›´æ–°æœ€ç»ˆè¿›åº¦ï¼ˆå¯¹äºæµå¼ä¸‹è½½ï¼Œè¿›åº¦å·²åœ¨å¾ªç¯ä¸­æ›´æ–°ï¼›å¯¹äºç›´æ¥è¯»å–ï¼Œè¿›åº¦ä¹Ÿå·²æ›´æ–°ï¼‰
                        if temp_file:
                            temp_file.flush()
                        
                        # å…³é—­æ–‡ä»¶
                        if temp_file:
                            temp_file.close()
                        
                        # éªŒè¯åˆ†ç‰‡å¤§å°
                        actual_size = os.path.getsize(temp_file_path)
                        if actual_size != expected_size:
                            raise Exception(f"åˆ†ç‰‡ {chunk_id} å¤§å°ä¸åŒ¹é…: æœŸæœ› {expected_size} å­—èŠ‚ï¼Œå®é™… {actual_size} å­—èŠ‚ / Chunk {chunk_id} size mismatch: expected {expected_size} bytes, got {actual_size} bytes")
                        
                        return chunk_id, True, temp_file_path
                    except Exception as e:
                        error_detail = f"åˆ†ç‰‡ {chunk_id} ä¸‹è½½å¤±è´¥: {str(e)} / Chunk {chunk_id} download failed: {str(e)}"
                        print(f"[é”™è¯¯] {error_detail}")
                        import traceback
                        traceback.print_exc()  # æ‰“å°å®Œæ•´å †æ ˆè·Ÿè¸ª
                        # ç¡®ä¿æ–‡ä»¶å·²å…³é—­
                        if temp_file:
                            try:
                                temp_file.close()
                            except:
                                pass
                        # æ¸…ç†å¤±è´¥çš„ä¸´æ—¶æ–‡ä»¶
                        if temp_file_path and os.path.exists(temp_file_path):
                            try:
                                os.unlink(temp_file_path)
                            except:
                                pass
                        return chunk_id, False, None
                    finally:
                        # ã€å…³é”®ä¿®å¤ã€‘åŠ¡å¿…å…³é—­ç‹¬ç«‹çš„Sessionï¼Œé‡Šæ”¾è¿æ¥èµ„æº
                        try:
                            local_session.close()
                        except:
                            pass
                
                # å¯åŠ¨å¤šçº¿ç¨‹ä¸‹è½½
                with ThreadPoolExecutor(max_workers=num_threads) as executor:
                    futures = []
                    for i in range(num_threads):
                        start = i * chunk_size
                        end = start + chunk_size - 1 if i < num_threads - 1 else total_size - 1
                        future = executor.submit(download_chunk, i, start, end)
                        futures.append(future)
                    
                    # æ˜¾ç¤ºè¿›åº¦å¹¶å®æ—¶å†™å…¥è¿›åº¦æ–‡ä»¶ï¼ˆä¾›å‰ç«¯è¯»å–ï¼‰
                    last_progress = 0
                    last_total_downloaded = 0
                    progress_updates = []
                    stall_count = 0  # æ£€æµ‹æ˜¯å¦å¡ä½
                    check_count = 0  # å¾ªç¯è®¡æ•°å™¨ï¼Œç”¨äºç»™åˆå§‹ä¸‹è½½ä¸€äº›ç¼“å†²æ—¶é—´
                    min_check_cycles = 15  # è‡³å°‘å¾ªç¯15æ¬¡ï¼ˆçº¦5ç§’ï¼‰åæ‰å¼€å§‹æ£€æµ‹åœæ»ï¼Œç»™ä¸‹è½½å¯åŠ¨æ—¶é—´
                    
                    while any(not f.done() for f in futures):
                        # ä½¿ç”¨é”è¯»å–è¿›åº¦æ•°ç»„ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
                        with lock:
                            total_downloaded = sum(downloaded_chunks)
                        
                        progress = (total_downloaded / total_size * 100) if total_size > 0 else 0
                        check_count += 1
                        
                        # åªåœ¨æœ‰å®é™…è¿›åº¦åï¼Œå¹¶ä¸”å·²ç»è¿‡äº†åˆå§‹ç¼“å†²æœŸï¼Œæ‰æ£€æµ‹åœæ»
                        has_progress = total_downloaded > 0
                        past_initial_period = check_count >= min_check_cycles
                        
                        # æ£€æµ‹è¿›åº¦æ˜¯å¦åœæ»ï¼ˆè¶…è¿‡15ç§’æ²¡æœ‰å˜åŒ–ï¼Œä¸”å·²ç»æœ‰äº†ä¸€äº›è¿›åº¦ï¼‰
                        if has_progress and past_initial_period and total_downloaded == last_total_downloaded:
                            stall_count += 1
                            # åªæœ‰è¶…è¿‡15ç§’ï¼ˆçº¦45ä¸ªå¾ªç¯ï¼‰æ²¡æœ‰è¿›å±•æ‰è­¦å‘Š
                            if stall_count >= 45:  # 15ç§’ï¼ˆ45 * 0.33ç§’ï¼‰
                                # æ˜¾ç¤ºæ¯ä¸ªçº¿ç¨‹çš„çŠ¶æ€
                                with lock:
                                    status_info = []
                                    for i in range(num_threads):
                                        chunk_start = i * chunk_size
                                        chunk_end = chunk_start + chunk_size - 1 if i < num_threads - 1 else total_size - 1
                                        chunk_total = chunk_end - chunk_start + 1
                                        chunk_progress = (downloaded_chunks[i] / chunk_total * 100) if chunk_total > 0 else 0
                                        is_done = futures[i].done()
                                        chunk_mb = downloaded_chunks[i] / 1024 / 1024
                                        total_mb = chunk_total / 1024 / 1024
                                        status_info.append(f"T{i}:{chunk_progress:.0f}%({chunk_mb:.1f}/{total_mb:.1f}MB){'âœ“' if is_done else 'â–¶'}")
                                    # åªåœ¨æœ‰å®é™…å¡ä½çš„åˆ†ç‰‡æ—¶æ‰æ˜¾ç¤ºè­¦å‘Šï¼ˆä¸æ˜¯æ‰€æœ‰çº¿ç¨‹éƒ½å®Œæˆäº†ï¼‰
                                    if any(not futures[i].done() for i in range(num_threads)):
                                        print(f"\nâš ï¸ è¿›åº¦å¯èƒ½åœæ» / Progress may be stalled: {' | '.join(status_info)}")
                                
                                stall_count = 0  # é‡ç½®è®¡æ•°å™¨
                        else:
                            stall_count = 0
                            last_total_downloaded = total_downloaded
                        
                        if int(progress) != last_progress:
                            progress_text = f"ä¸‹è½½è¿›åº¦ / Download progress: {progress:.1f}% ({total_downloaded / 1024 / 1024:.2f} MB / {total_size / 1024 / 1024:.2f} MB)"
                            print(f"\r{progress_text}", end='', flush=True)
                            last_progress = int(progress)
                            
                            # ä¿å­˜æœ€æ–°çš„è¿›åº¦æ›´æ–°
                            progress_updates.append(progress_text)
                            if len(progress_updates) > 10:
                                progress_updates.pop(0)  # åªä¿ç•™æœ€è¿‘10æ¡
                        
                        time.sleep(0.33)  # çº¦æ¯0.33ç§’æ›´æ–°ä¸€æ¬¡ï¼ˆæ›´é¢‘ç¹ä»¥æ£€æµ‹åœæ»ï¼‰
                    
                    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
                    results = [f.result() for f in futures]
                    
                    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åˆ†ç‰‡éƒ½ä¸‹è½½æˆåŠŸ
                    failed_chunks = [r[0] for r in results if not r[1]]
                    if failed_chunks:
                        # æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
                        for i in range(num_threads):
                            if i in temp_files:
                                try:
                                    os.unlink(temp_files[i])
                                except:
                                    pass
                        raise Exception(f"éƒ¨åˆ†åˆ†ç‰‡ä¸‹è½½å¤±è´¥ / Some chunks failed to download: {failed_chunks}")
                
                print()  # æ¢è¡Œ
                
                # åˆå¹¶åˆ†ç‰‡ï¼ˆæŒ‰ chunk_id é¡ºåºåˆå¹¶ï¼Œç¡®ä¿æ–‡ä»¶é¡ºåºæ­£ç¡®ï¼‰
                print("åˆå¹¶ä¸‹è½½çš„åˆ†ç‰‡... / Merging downloaded chunks...")
                try:
                    # ä½¿ç”¨æµå¼åˆå¹¶ï¼Œé¿å…å¤§æ–‡ä»¶ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜
                    chunk_copy_size = 64 * 1024 * 1024  # æ¯æ¬¡å¤åˆ¶64MBï¼Œé€‚åˆå¤§æ–‡ä»¶
                    with open(save_path, 'wb') as f:
                        for i in range(num_threads):
                            if i not in temp_files:
                                raise Exception(f"åˆ†ç‰‡ {i} çš„ä¸´æ—¶æ–‡ä»¶ä¸å­˜åœ¨ / Temporary file for chunk {i} does not exist")
                            temp_file_path = temp_files[i]
                            if not os.path.exists(temp_file_path):
                                raise Exception(f"åˆ†ç‰‡ {i} çš„ä¸´æ—¶æ–‡ä»¶ä¸å­˜åœ¨ / Temporary file for chunk {i} does not exist: {temp_file_path}")
                            
                            # æµå¼å¤åˆ¶ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½å¤§æ–‡ä»¶åˆ°å†…å­˜
                            with open(temp_file_path, 'rb') as tf:
                                while True:
                                    chunk_data = tf.read(chunk_copy_size)
                                    if not chunk_data:
                                        break
                                    f.write(chunk_data)
                            
                            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                            os.unlink(temp_file_path)
                    
                    # éªŒè¯æœ€ç»ˆæ–‡ä»¶å¤§å°
                    final_size = os.path.getsize(save_path)
                    if final_size != total_size:
                        raise Exception(f"æ–‡ä»¶å¤§å°ä¸åŒ¹é…: æœŸæœ› {total_size} å­—èŠ‚ï¼Œå®é™… {final_size} å­—èŠ‚ / File size mismatch: expected {total_size} bytes, got {final_size} bytes")
                    
                except Exception as e:
                    # æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
                    for i in range(num_threads):
                        if i in temp_files:
                            try:
                                if os.path.exists(temp_files[i]):
                                    os.unlink(temp_files[i])
                            except:
                                pass
                    # å¦‚æœæœ€ç»ˆæ–‡ä»¶å·²åˆ›å»ºä½†ä¸å®Œæ•´ï¼Œåˆ é™¤å®ƒ
                    if os.path.exists(save_path):
                        try:
                            os.unlink(save_path)
                        except:
                            pass
                    raise
                
                
            else:
                # å•çº¿ç¨‹ä¸‹è½½ï¼ˆä¸æ”¯æŒ Range æˆ–æ–‡ä»¶å¤§å°æœªçŸ¥ï¼‰
                print("ä½¿ç”¨å•çº¿ç¨‹ä¸‹è½½... / Using single-threaded download...")
                # åˆ›å»ºç‹¬ç«‹çš„Sessionç”¨äºå•çº¿ç¨‹ä¸‹è½½
                with requests.Session() as single_session:
                    single_session.headers.update({
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    })
                    response = single_session.get(url, stream=True, timeout=(30, 300))
                    response.raise_for_status()
                    
                    downloaded_size = 0
                    block_size = 4 * 1024 * 1024  # 4MB å—å¤§å°
                    
                    with open(save_path, 'wb') as f:
                        if total_size > 0:
                            last_write_time = 0
                            with tqdm(total=total_size, unit='B', unit_scale=True, desc=filename) as pbar:
                                for chunk in response.iter_content(chunk_size=block_size):
                                    if chunk:
                                        f.write(chunk)
                                        downloaded_size += len(chunk)
                                        pbar.update(len(chunk))
                                        progress = (downloaded_size / total_size * 100) if total_size > 0 else 0
                                        progress_text = f"ä¸‹è½½è¿›åº¦ / Download progress: {progress:.1f}% ({downloaded_size / 1024 / 1024:.2f} MB / {total_size / 1024 / 1024:.2f} MB)"
                                        print(f"\r{progress_text}", end='', flush=True)
                                        
                        else:
                            for chunk in response.iter_content(chunk_size=block_size):
                                if chunk:
                                    f.write(chunk)
                                    downloaded_size += len(chunk)
                                    print(f"\rå·²ä¸‹è½½ / Downloaded: {downloaded_size / 1024 / 1024:.2f} MB", end='', flush=True)
                            print()  # æ¢è¡Œ
            
            print(f"âœ“ ä¸‹è½½å®Œæˆ / Download completed: {save_path}")
            print("âš ï¸ è¯·é‡å¯ ComfyUI ä»¥ä½¿æ–°ä¸‹è½½çš„æ¨¡å‹ç”Ÿæ•ˆ / Please restart ComfyUI for the newly downloaded model to take effect")
            
            # æ„å»ºæœ€ç»ˆæ¶ˆæ¯ï¼ˆä¸åŒ…å«è¿›åº¦ä¿¡æ¯å’Œä¿å­˜è·¯å¾„ï¼‰
            final_msg = f"âœ“ ä¸‹è½½å®Œæˆ / Download completed: {save_path}\nâš ï¸ è¯·é‡å¯ ComfyUI ä»¥ä½¿æ–°ä¸‹è½½çš„æ¨¡å‹ç”Ÿæ•ˆ / Please restart ComfyUI for the newly downloaded model to take effect"
            return {"ui": {"text": [final_msg]}}
            
        except requests.exceptions.RequestException as e:
            error_msg = f"ä¸‹è½½å¤±è´¥ / Download failed: {str(e)}"
            print(error_msg)
            return {"ui": {"text": [error_msg]}}
        except Exception as e:
            error_msg = f"å‘ç”Ÿé”™è¯¯ / Error occurred: {str(e)}"
            print(error_msg)
            return {"ui": {"text": [error_msg]}}


class HiveNodeInstaller:
    """
    èŠ‚ç‚¹å®‰è£…å™¨
    ç”¨æˆ·å¯ä»¥ç²˜è´´èŠ‚ç‚¹çš„å®‰è£…åœ°å€ï¼ˆGitHub/GitLab/Giteeç­‰ï¼‰ï¼Œè‡ªåŠ¨å®‰è£…åˆ° ComfyUI çš„ custom_nodes ç›®å½•
    """
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "url": ("STRING", {
                    "name": "èŠ‚ç‚¹å®‰è£…åœ°å€/node installation address",
                    "tooltip": "è¯·å°†èŠ‚ç‚¹å®‰è£…åœ°å€ç²˜è´´è¿›æ¥ï¼ˆGitHub/GitLab/Giteeç­‰ï¼‰ / please paste the node installation address here (GitHub/GitLab/Gitee etc.)",
                    "multiline": False,
                    "default": "",
                    "placeholder": "è¯·å°†èŠ‚ç‚¹å®‰è£…åœ°å€ç²˜è´´è¿›æ¥ï¼ˆGitHub/GitLab/Giteeç­‰ï¼‰",
                }),
            },
            "optional": {}
        }
    
    RETURN_TYPES = ()
    FUNCTION = "install_node"
    OUTPUT_NODE = True
    CATEGORY = "Hive/Install"
    # æ³¨æ„è¯­è¨€æ–‡ä»¶ä¸­ä¸èƒ½ç”¨@ç¬¦å·
    DESCRIPTION = "èŠ‚ç‚¹å®‰è£…å™¨ - ç²˜è´´èŠ‚ç‚¹çš„å®‰è£…åœ°å€ï¼ˆGitHub/GitLab/Giteeç­‰ï¼‰ï¼Œè‡ªåŠ¨å®‰è£…åˆ° ComfyUI çš„ custom_nodes ç›®å½•ã€‚æ”¯æŒ Git ä»“åº“å’Œ ZIP æ–‡ä»¶å®‰è£…ã€‚/ Node installer - paste the installation address of nodes (GitHub/GitLab/Gitee, etc.) and automatically install them to ComfyUI's custom_nodes directory. Supports Git repository and ZIP file installation. - Github: https://github.com/luguoli - ğŸ“§Email: luguoliï¹«vip.qq.com"
    
    def find_comfyui_custom_nodes_dir(self):
        """
        æŸ¥æ‰¾ ComfyUI çš„ custom_nodes ç›®å½•
        
        Returns:
            custom_nodes ç›®å½•è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å› None
        """
        current_dir = os.path.dirname(os.path.abspath(__file__))
        
        # æ–¹æ³•1: å½“å‰æ–‡ä»¶å°±åœ¨ custom_nodes ç›®å½•ä¸‹
        if os.path.basename(os.path.dirname(current_dir)) == "custom_nodes":
            return os.path.dirname(current_dir)
        
        # æ–¹æ³•2: å‘ä¸ŠæŸ¥æ‰¾ custom_nodes ç›®å½•
        check_dir = current_dir
        for _ in range(5):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾5å±‚
            if os.path.basename(check_dir) == "custom_nodes":
                return check_dir
            parent = os.path.dirname(check_dir)
            if parent == check_dir:
                break
            check_dir = parent
        
        # æ–¹æ³•3: æŸ¥æ‰¾ ComfyUI æ ¹ç›®å½•ä¸‹çš„ custom_nodes
        check_dir = current_dir
        for _ in range(5):
            custom_nodes_path = os.path.join(check_dir, "custom_nodes")
            if os.path.exists(custom_nodes_path) and os.path.isdir(custom_nodes_path):
                return custom_nodes_path
            parent = os.path.dirname(check_dir)
            if parent == check_dir:
                break
            check_dir = parent
        
        return None
    
    def normalize_git_url(self, url):
        """
        è§„èŒƒåŒ– Git URL
        
        Args:
            url: åŸå§‹ URL
        
        Returns:
            è§„èŒƒåŒ–åçš„ Git URL
        """
        url = url.strip()
        
        # ç§»é™¤æœ«å°¾çš„æ–œæ 
        url = url.rstrip('/')
        
        # å¦‚æœæ˜¯ GitHub/GitLab/Gitee çš„ç½‘é¡µé“¾æ¥ï¼Œè½¬æ¢ä¸º Git URL
        if 'github.com' in url or 'gitlab.com' in url or 'gitee.com' in url:
            # ç§»é™¤ .git åç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
            if url.endswith('.git'):
                url = url[:-4]
            
            # å¦‚æœæ˜¯ç½‘é¡µé“¾æ¥ï¼ˆåŒ…å« /tree/ æˆ– /blob/ï¼‰ï¼Œæå–ä»“åº“æ ¹ URL
            if '/tree/' in url or '/blob/' in url:
                parts = url.split('/')
                # æ‰¾åˆ°ä»“åº“ååçš„ç¬¬ä¸€ä¸ªç‰¹æ®Šè·¯å¾„ï¼ˆtree/blobï¼‰
                repo_index = None
                for i, part in enumerate(parts):
                    if part in ['tree', 'blob']:
                        repo_index = i
                        break
                if repo_index:
                    url = '/'.join(parts[:repo_index])
            
            # ç¡®ä¿æ˜¯ HTTPS URL
            if not url.startswith('http://') and not url.startswith('https://'):
                url = 'https://' + url
            
            # æ·»åŠ  .git åç¼€
            if not url.endswith('.git'):
                url = url + '.git'
        
        return url
    
    def install_node(self, url):
        """
        å®‰è£…èŠ‚ç‚¹
        
        Args:
            url: èŠ‚ç‚¹çš„å®‰è£…åœ°å€ï¼ˆGit ä»“åº“ URL æˆ– ZIP æ–‡ä»¶ URLï¼‰
        
        Returns:
            status: å®‰è£…çŠ¶æ€ä¿¡æ¯
        """
        if not url or not url.strip():
            return {"ui": {"text": ["é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„å®‰è£…åœ°å€ / Error: Please provide a valid installation URL"]}}
        
        url = url.strip()
        
        try:
            # æŸ¥æ‰¾ custom_nodes ç›®å½•
            custom_nodes_dir = self.find_comfyui_custom_nodes_dir()
            
            if not custom_nodes_dir:
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•ä½¿ç”¨å½“å‰ç›®å½•çš„çˆ¶ç›®å½•
                current_dir = os.path.dirname(os.path.abspath(__file__))
                custom_nodes_dir = os.path.join(os.path.dirname(current_dir), "custom_nodes")
                os.makedirs(custom_nodes_dir, exist_ok=True)
                print(f"è­¦å‘Š: æœªæ‰¾åˆ° ComfyUI custom_nodes ç›®å½•ï¼Œä½¿ç”¨ / Warning: ComfyUI custom_nodes directory not found, using: {custom_nodes_dir}")
            else:
                print(f"æ‰¾åˆ° custom_nodes ç›®å½• / Found custom_nodes directory: {custom_nodes_dir}")
            
            # åˆ¤æ–­æ˜¯ Git ä»“åº“è¿˜æ˜¯ ZIP æ–‡ä»¶
            is_git_repo = any(domain in url.lower() for domain in ['github.com', 'gitlab.com', 'gitee.com', 'git@'])
            is_zip_file = url.lower().endswith('.zip') or '/archive/' in url.lower()
            
            if is_git_repo and not is_zip_file:
                # Git ä»“åº“å®‰è£…
                return self._install_from_git(url, custom_nodes_dir)
            else:
                # ZIP æ–‡ä»¶å®‰è£…
                return self._install_from_zip(url, custom_nodes_dir)
                
        except Exception as e:
            error_msg = f"å®‰è£…å¤±è´¥ / Installation failed: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return (error_msg,)
    
    def _install_from_git(self, url, custom_nodes_dir):
        """
        ä» Git ä»“åº“å®‰è£…èŠ‚ç‚¹
        
        Args:
            url: Git ä»“åº“ URL
            custom_nodes_dir: custom_nodes ç›®å½•è·¯å¾„
        
        Returns:
            status: å®‰è£…çŠ¶æ€ä¿¡æ¯
        """
        try:
            # è§„èŒƒåŒ– URL
            git_url = self.normalize_git_url(url)
            
            # æå–ä»“åº“åç§°
            repo_name = os.path.basename(git_url).replace('.git', '')
            if not repo_name:
                # å¦‚æœæ— æ³•æå–ï¼Œä½¿ç”¨ URL çš„ä¸€éƒ¨åˆ†
                repo_name = git_url.split('/')[-1].replace('.git', '')
            
            install_path = os.path.join(custom_nodes_dir, repo_name)
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(install_path):
                # å¦‚æœå·²å­˜åœ¨ï¼Œå°è¯•æ›´æ–°ï¼ˆä½¿ç”¨ git pullï¼‰
                print(f"èŠ‚ç‚¹å·²å­˜åœ¨ / Node already exists: {install_path}")
                print("å°è¯•æ›´æ–°èŠ‚ç‚¹... / Attempting to update node...")
                try:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ git ä»“åº“
                    git_dir = os.path.join(install_path, '.git')
                    if os.path.exists(git_dir):
                        # ä½¿ç”¨ git pull æ›´æ–°
                        process = subprocess.Popen(
                            ['git', 'pull'],
                            cwd=install_path,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.STDOUT,
                            universal_newlines=True,
                            bufsize=1
                        )
                        output_lines = []
                        for line in process.stdout:
                            line = line.strip()
                            if line:
                                print(line)
                                output_lines.append(line)
                        process.wait()
                        
                        if process.returncode == 0:
                            print(f"âœ“ æ›´æ–°å®Œæˆ / Update completed: {install_path}")
                            print("âš ï¸ è¯·é‡å¯ ComfyUI ä»¥ä½¿æ–°å®‰è£…çš„èŠ‚ç‚¹ç”Ÿæ•ˆ / Please restart ComfyUI for the newly installed node to take effect")
                            return {"ui": {"text": [f"âœ“ æ›´æ–°å®Œæˆ / Update completed: {install_path}\nâš ï¸ è¯·é‡å¯ ComfyUI ä»¥ä½¿æ–°å®‰è£…çš„èŠ‚ç‚¹ç”Ÿæ•ˆ / Please restart ComfyUI for the newly installed node to take effect"]}}
                        else:
                            return {"ui": {"text": [f"æ›´æ–°å¤±è´¥ï¼Œè¿”å›ç  / Update failed, return code: {process.returncode}\nè¯·æ‰‹åŠ¨åˆ é™¤ {install_path} åé‡æ–°å®‰è£… / Please manually delete {install_path} and reinstall"]}}
                    else:
                        # ä¸æ˜¯ git ä»“åº“ï¼Œéœ€è¦åˆ é™¤åé‡æ–°å®‰è£…
                        return {"ui": {"text": [f"èŠ‚ç‚¹å·²å­˜åœ¨ä½†ä¸æ˜¯ Git ä»“åº“ / Node exists but is not a Git repository: {install_path}\nå¦‚éœ€é‡æ–°å®‰è£…ï¼Œè¯·æ‰‹åŠ¨åˆ é™¤è¯¥ç›®å½•åå†æ¬¡è¿è¡Œ / To reinstall, please manually delete this directory and run again"]}}
                except Exception as e:
                    return {"ui": {"text": [f"æ›´æ–°å¤±è´¥ / Update failed: {str(e)}\nè¯·æ‰‹åŠ¨åˆ é™¤ {install_path} åé‡æ–°å®‰è£… / Please manually delete {install_path} and reinstall"]}}
            
            print(f"å¼€å§‹å…‹éš†ä»“åº“ / Starting to clone repository: {git_url}")
            print(f"å®‰è£…åˆ° / Installing to: {install_path}")
            
            # æ£€æŸ¥ git æ˜¯å¦å¯ç”¨
            try:
                subprocess.run(['git', '--version'], check=True, capture_output=True)
            except (subprocess.CalledProcessError, FileNotFoundError):
                return {"ui": {"text": ["é”™è¯¯: æœªæ‰¾åˆ° git å‘½ä»¤ï¼Œè¯·å…ˆå®‰è£… Git / Error: Git command not found, please install Git first"]}}
            
            # å…‹éš†ä»“åº“
            # ä½¿ç”¨ subprocess å¹¶æ˜¾ç¤ºè¿›åº¦
            process = subprocess.Popen(
                ['git', 'clone', '--progress', git_url, install_path],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True,
                bufsize=1
            )
            
            # å®æ—¶è¾“å‡ºè¿›åº¦
            output_lines = []
            for line in process.stdout:
                line = line.strip()
                if line:
                    print(line)
                    output_lines.append(line)
            
            process.wait()
            
            if process.returncode == 0:
                print(f"âœ“ å®‰è£…å®Œæˆ / Installation completed: {install_path}")
                print("âš ï¸ è¯·é‡å¯ ComfyUI ä»¥ä½¿æ–°å®‰è£…çš„èŠ‚ç‚¹ç”Ÿæ•ˆ / Please restart ComfyUI for the newly installed node to take effect")
                return {"ui": {"text": [f"âœ“ å®‰è£…å®Œæˆ / Installation completed: {install_path}\nâš ï¸ è¯·é‡å¯ ComfyUI ä»¥ä½¿æ–°å®‰è£…çš„èŠ‚ç‚¹ç”Ÿæ•ˆ / Please restart ComfyUI for the newly installed node to take effect"]}}
            else:
                error_msg = f"Git å…‹éš†å¤±è´¥ï¼Œè¿”å›ç  / Git clone failed, return code: {process.returncode}"
                print(error_msg)
                return {"ui": {"text": [error_msg]}}
                
        except Exception as e:
            error_msg = f"Git å®‰è£…å¤±è´¥ / Git installation failed: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return {"ui": {"text": [error_msg]}}
    
    def _install_from_zip(self, url, custom_nodes_dir):
        """
        ä» ZIP æ–‡ä»¶å®‰è£…èŠ‚ç‚¹
        
        Args:
            url: ZIP æ–‡ä»¶ URL
            custom_nodes_dir: custom_nodes ç›®å½•è·¯å¾„
        
        Returns:
            status: å®‰è£…çŠ¶æ€ä¿¡æ¯
        """
        try:
            print(f"å¼€å§‹ä¸‹è½½ ZIP æ–‡ä»¶ / Starting to download ZIP file: {url}")
            
            # ä¸‹è½½ ZIP æ–‡ä»¶ - ä¼˜åŒ–ä¸‹è½½é€Ÿåº¦
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            response = session.get(url, stream=True, timeout=(30, 300))  # è¿æ¥è¶…æ—¶30ç§’ï¼Œè¯»å–è¶…æ—¶300ç§’
            response.raise_for_status()
            
            # è·å–æ–‡ä»¶å¤§å°
            total_size = int(response.headers.get('content-length', 0))
            
            # ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.zip')
            temp_path = temp_file.name
            
            try:
                downloaded_size = 0
                block_size = 2 * 1024 * 1024  # 2MB å—å¤§å°ï¼ˆæé«˜ä¸‹è½½é€Ÿåº¦ï¼‰
                
                with open(temp_path, 'wb') as f:
                    if total_size > 0:
                        with tqdm(total=total_size, unit='B', unit_scale=True, desc="ä¸‹è½½ä¸­ / Downloading") as pbar:
                            for chunk in response.iter_content(chunk_size=block_size):
                                if chunk:
                                    f.write(chunk)
                                    downloaded_size += len(chunk)
                                    pbar.update(len(chunk))
                    else:
                        for chunk in response.iter_content(chunk_size=block_size):
                            if chunk:
                                f.write(chunk)
                                downloaded_size += len(chunk)
                                print(f"\rå·²ä¸‹è½½ / Downloaded: {downloaded_size / 1024 / 1024:.2f} MB", end='', flush=True)
                        print()
                
                print("å¼€å§‹è§£å‹... / Starting to extract...")
                
                # è§£å‹ ZIP æ–‡ä»¶
                with zipfile.ZipFile(temp_path, 'r') as zip_ref:
                    # è·å– ZIP æ–‡ä»¶ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨
                    file_list = zip_ref.namelist()
                    
                    # æŸ¥æ‰¾æ ¹ç›®å½•åç§°ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªç›®å½•ï¼‰
                    root_dir = None
                    for name in file_list:
                        if '/' in name:
                            root_dir = name.split('/')[0]
                            break
                    
                    # æ£€æŸ¥æ ¹ç›®å½•æ˜¯å¦å·²å­˜åœ¨
                    if root_dir:
                        extracted_path = os.path.join(custom_nodes_dir, root_dir)
                        if os.path.exists(extracted_path):
                            print(f"è­¦å‘Š: èŠ‚ç‚¹ç›®å½•å·²å­˜åœ¨ / Warning: Node directory already exists: {extracted_path}")
                            print("å°†è¦†ç›–ç°æœ‰æ–‡ä»¶... / Will overwrite existing files...")
                    
                    # è§£å‹æ–‡ä»¶
                    total_files = len(file_list)
                    extracted = 0
                    
                    with tqdm(total=total_files, unit='files', desc="è§£å‹ä¸­ / Extracting") as pbar:
                        for member in zip_ref.namelist():
                            zip_ref.extract(member, custom_nodes_dir)
                            extracted += 1
                            pbar.update(1)
                    
                    # å¦‚æœ ZIP æ–‡ä»¶åŒ…å«å•ä¸ªæ ¹ç›®å½•ï¼Œæ˜¾ç¤ºå®‰è£…è·¯å¾„
                    if root_dir:
                        extracted_path = os.path.join(custom_nodes_dir, root_dir)
                        print(f"èŠ‚ç‚¹å®‰è£…è·¯å¾„ / Node installation path: {extracted_path}")
                
                print(f"âœ“ å®‰è£…å®Œæˆ / Installation completed: {custom_nodes_dir}")
                print("âš ï¸ è¯·é‡å¯ ComfyUI ä»¥ä½¿æ–°å®‰è£…çš„èŠ‚ç‚¹ç”Ÿæ•ˆ / Please restart ComfyUI for the newly installed node to take effect")
                return {"ui": {"text": [f"âœ“ å®‰è£…å®Œæˆ / Installation completed: {custom_nodes_dir}\nâš ï¸ è¯·é‡å¯ ComfyUI ä»¥ä½¿æ–°å®‰è£…çš„èŠ‚ç‚¹ç”Ÿæ•ˆ / Please restart ComfyUI for the newly installed node to take effect"]}}
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                    
        except zipfile.BadZipFile:
            error_msg = "é”™è¯¯: ä¸‹è½½çš„æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ ZIP æ–‡ä»¶ / Error: The downloaded file is not a valid ZIP file"
            print(error_msg)
            return {"ui": {"text": [error_msg]}}
        except Exception as e:
            error_msg = f"ZIP å®‰è£…å¤±è´¥ / ZIP installation failed: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return {"ui": {"text": [error_msg]}}


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "HiveModelDownloader": HiveModelDownloader,
    "HiveNodeInstaller": HiveNodeInstaller,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "HiveModelDownloader": "Hive æ¨¡å‹ä¸‹è½½å™¨/Model Downloader - Github:ï¹«luguoli",
    "HiveNodeInstaller": "Hive èŠ‚ç‚¹å®‰è£…å™¨/Node Installer - Github:ï¹«luguoli",
}

